services:
  mcp-server-sdk:
    build:
      context: ./mcp_server_py
      dockerfile: Dockerfile
    container_name: mcp-server-sdk
    environment:
      - NEMO_DATA_DESIGNER_URL=http://nemo-microservices-envoy-gateway-1:8000
      - NEMO_BASE_URL=http://nemo-microservices-envoy-gateway-1:8000
      - NIM_API_KEY=${NIM_API_KEY}
      - LITE_LLM_KEY=${LITELLM_KEY}
      - MCP_TRANSPORT=sse
      - MCP_PORT=8002
      - PYTHONPATH=/
      - S3_ARTIFACTS_BUCKET=nemo-data-designer-artifacts-668102661106
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_SESSION_TOKEN=${AWS_SESSION_TOKEN}
      - AWS_REGION=${AWS_REGION:-us-east-1}
    ports:
      - "8002:8002"
    command: python /mcp_server_py/server_sdk.py
    volumes:
      - ./mcp_server_py:/mcp_server_py
      - ./langgraph:/langgraph
      - ./data-designer-output:/tmp/data-designer-output
    networks:
      - nemo-microservices_nmp

  streamlit-ui:
    build:
      context: ./streamlit_app
      dockerfile: Dockerfile
    container_name: streamlit-ui
    environment:
      - MCP_SERVER_URL=http://mcp-server-sdk:8002/sse
      - LANGGRAPH_SERVER_URL=http://langgraph-server:8003
      - DATA_OUTPUT_DIR=/data-designer-output
      - LLM_BASE_URL=http://host.docker.internal:4000/v1
      - LLM_MODEL=bedrock-claude-haiku
      - LLM_API_KEY=${LITELLM_KEY}
      - S3_ARTIFACTS_BUCKET=nemo-data-designer-artifacts-668102661106
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_SESSION_TOKEN=${AWS_SESSION_TOKEN}
      - AWS_REGION=${AWS_REGION:-us-east-1}
    ports:
      - "8501:8501"
    volumes:
      - ./streamlit_app:/app
      - ./data-designer-output:/data-designer-output
    depends_on:
      - mcp-server-sdk
      - langgraph-server
    networks:
      - nemo-microservices_nmp

  langgraph-server:
    build:
      context: ./langgraph
      dockerfile: Dockerfile.server
    container_name: langgraph-server
    environment:
      - MCP_SERVER_URL=http://mcp-server-sdk:8002/sse
      - LLM_BASE_URL=http://host.docker.internal:4000/v1
      - LLM_MODEL=bedrock-claude-haiku
      - LLM_API_KEY=${LITELLM_KEY}
    ports:
      - "8003:8003"
    depends_on:
      - mcp-server-sdk
    networks:
      - nemo-microservices_nmp

networks:
  nemo-microservices_nmp:
    external: true

volumes:
  pgdata: {}
